{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyMalTin/05yBSvJDPnRgx4k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mk0OO5UA_SRG"},"outputs":[],"source":["import torch\n","import torch.nn as nn # for building modules and layers\n","import torch.optim as optim # contains optimization algorithms"]},{"cell_type":"code","source":["# sample data\n","\n","# linspace creates 100 evenly spaced numbers between -1 and 1\n","# unsqueeze reshapes the tensor to have a colum dimension of 1\n","x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1)\n","\n","# y is generated using the equation 2 * x + 1 with some noise added\n","# .randn(x.size()) generates noise with same shapes as x\n","y = 2 * x + 0.2 * torch.randn(x.size())\n","\n","\n","# sample model\n","# nn.Sequential: a container module that sequences a list of layers or modules in the order they are added\n","# it is useful for simple models which involves stacking layers\n","\n","model = nn.Sequential(\n","\n","    # nn.Linear: a built in layer that automatically creates weights and bias\n","    # in_features and out_features: feature size respectively for inputs and outputs\n","    nn.Linear(in_features=1, out_features=1) # a perceptron that applies the transformation x* weight + bias\n",")\n","\n"],"metadata":{"id":"Wk9QSHTA_a6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss function: how far off the predictions are from true values, measurement is done via loss function\n","# nn.MSELoss: computes the mean squared error between the predicted values and target values\n","loss_function = nn.MSELoss()\n","\n","# optimizer: updates the model's parameters (weights and bias) baed on gradients computed during backward propagation\n","# stoachastic gradient descent is one of the optimizer available from the optimizer module\n","# learning rate: controls the size of the steps taken towards minimizing loss function\n","optimizer = optim.SGD(model.parameters(), lr=0.01) # weights and bias are made availble by the nn.Linear which is used to build the model"],"metadata":{"id":"tEVDHoIDB-zs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training the model\n","# training involves forward propagation, loss calculation, back prpagation, and parameter update\n","\n","# epoch: number of loops for training\n","epochs = 100\n","\n","# learning rate: the amount of step that the model takes to correct or minimize loss in each step\n","learning_rate = 0.01\n","\n","for epoch in range(epochs):\n","\n","    model.train() # set the model in training model\n","\n","    optimizer.zero_grad() #zero out previous gradients as pytorch accumulates gradients by default\n","\n","    outputs = model(x) # input data x is passed through the model computes the function and gives predictions based on internal parameters\n","\n","    loss = loss_function(outputs, y) # outputs generated by the model are compared by real values and loss is calculated\n","\n","    loss.backward() # back propagation: computes the gradient of loss with respect to each parameters and tells how to change each weight and bias to reduce the loss\n","\n","    optimizer.step() # uses the computed gradients to adjust weights and bias\n","\n","\n","    # print loss for every 10 epochs to monitor the progress\n","    if (epoch + 1) % 10 == 0:\n","        print(f'Epoch: [epoch{(epoch+1)/100}], loss: {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UW-W2yjzDSIy","executionInfo":{"status":"ok","timestamp":1742046835881,"user_tz":-330,"elapsed":91,"user":{"displayName":"N K","userId":"04064883306889132122"}},"outputId":"ae44c60a-e360-4a1c-d6cb-2c9edfbaf899"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [epoch0.1], loss: 1.7647\n","Epoch: [epoch0.2], loss: 1.5361\n","Epoch: [epoch0.3], loss: 1.3394\n","Epoch: [epoch0.4], loss: 1.1696\n","Epoch: [epoch0.5], loss: 1.0227\n","Epoch: [epoch0.6], loss: 0.8953\n","Epoch: [epoch0.7], loss: 0.7848\n","Epoch: [epoch0.8], loss: 0.6887\n","Epoch: [epoch0.9], loss: 0.6051\n","Epoch: [epoch1.0], loss: 0.5324\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"],"metadata":{"id":"iaCLbLSfFlVW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.unsqueeze(torch.linspace(-1, 1, 100), 1)\n","y = 2 * x + 1 + 0.2 * torch.randn(x.size())\n","\n","model = nn.Sequential(\n","    nn.Linear(in_features=1, out_features=1)\n",")\n","\n","loss_function = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","epochs = 1000\n","for epoch in range(epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","    outputs = model(x)\n","    loss = loss_function(outputs, y)\n","    loss.backward()\n","    optimizer.step()\n","\n","model_input = 3.2\n","test_input = torch.tensor([[model_input]])\n","predicted = model(test_input)\n","print(f\"for input {3.2 * 2}, predicted output: {predicted.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5AazV45K21S","executionInfo":{"status":"ok","timestamp":1742048832219,"user_tz":-330,"elapsed":90,"user":{"displayName":"N K","userId":"04064883306889132122"}},"outputId":"fd3c4248-a74a-489d-eeb5-972b09a34bf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["for input 6.4, predicted output: 7.500495910644531\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import make_regression\n","\n","X,y = make_regression(n_samples=100, n_features=1, random_state=42)\n","X = torch.tensor(X, dtype=torch.float32)\n","y = torch.tensor(y, dtype=torch.float32)\n","\n","simple_regression_model = nn.Sequential(\n","    nn.Linear(in_features=1, out_features=1)\n",")\n","\n","loss_function = nn.MSELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.001)\n","\n","num_epochs = 1000\n","\n","for epoch in range(num_epochs):\n","    simple_regression_model.train()\n","    optimizer.zero_grad()\n","    outputs = simple_regression_model(X)\n","    loss = loss_function(outputs, y)\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","test_input =  torch.tensor([0.3])\n","predicted = model(test_input)\n","print(predicted.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRtLJP7ONFcf","executionInfo":{"status":"ok","timestamp":1742050237568,"user_tz":-330,"elapsed":506,"user":{"displayName":"N K","userId":"04064883306889132122"}},"outputId":"9ae973b0-7234-4db4-a03a-8838c2a1c613"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"stream","name":"stdout","text":["1.6095908880233765\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import make_regression\n","from sklearn.model_selection import train_test_split\n","\n","\n","X,y = make_regression(n_samples=100, n_features=1, random_state=32)\n","X = torch.tensor(X, dtype=torch.float32)\n","y = torch.tensor(y, dtype=torch.float32)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=32)\n","\n","train_test_regression_model = nn.Sequential(\n","    nn.Linear(in_features=1, out_features=1)\n",")\n","\n","loss_function = nn.MSELoss()\n","optimizer = optim.SGD(train_test_regression_model.parameters(), lr=0.01)\n","\n","num_epochs = 10000\n","for epoch in range(num_epochs):\n","    train_test_regression_model.train()\n","\n","    optimizer.zero_grad()\n","    outputs = train_test_regression_model(X_train)\n","    loss = loss_function(outputs, y_train)\n","    loss.backward()\n","    optimizer.step()\n","\n","    if (epoch+1) % 100 ==1:\n","        print(f'{loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXdwcO0WPOfu","executionInfo":{"status":"ok","timestamp":1742050461122,"user_tz":-330,"elapsed":3499,"user":{"displayName":"N K","userId":"04064883306889132122"}},"outputId":"e9acb04e-496d-4310-f4ef-86c871471b5f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["862.0627\n","852.6576\n","852.4752\n","852.4695\n","852.4691\n","852.4691\n","852.4690\n","852.4690\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n","852.4691\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    test_outputs = train_test_regression_model(X_test)\n","    test_loss = loss_function(test_outputs, y_test)\n","    print(test_loss.item())\n","test_input = X_test\n","predicted = train_test_regression_model(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnGKl-GvQwi-","executionInfo":{"status":"ok","timestamp":1742050618322,"user_tz":-330,"elapsed":16,"user":{"displayName":"N K","userId":"04064883306889132122"}},"outputId":"aeb1b0fa-8ad9-4dec-a3e8-7337713ddcfd"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1746.483154296875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([80])) that is different to the input size (torch.Size([80, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_iris\n","from sklearn.preprocessing import StandardScaler\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","scalar = StandardScaler()\n","X = scalar.fit_transform(X)\n","\n","X = torch.tensor(X, dtype=torch.float32)\n","y = torch.tensor(y, dtype=torch.int64)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","model = nn.Sequential(\n","    nn.Linear(4, 10),\n","    nn.ReLU(),\n","    nn.Linear(10, 3)\n",")\n","\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","num_epochs = 500\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    outputs = model(X_train)\n","    loss = loss_function(outputs, y_train)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","with torch.no_grad():\n","    outputs = model(X_test)\n","    _,predicted = torch.max(outputs, 1)\n","    accuracy = (predicted == y_test).float().mean()\n","    print(accuracy.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTD6eCAhVXOT","executionInfo":{"status":"ok","timestamp":1742052577172,"user_tz":-330,"elapsed":5928,"user":{"displayName":"N K","userId":"04064883306889132122"}},"outputId":"3ad16f0d-3f66-406e-fc5e-ac3effad70c5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8999999761581421\n"]}]}]}